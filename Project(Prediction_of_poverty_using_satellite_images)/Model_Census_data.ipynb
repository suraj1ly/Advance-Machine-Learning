{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T15:00:20.923284Z",
     "start_time": "2019-11-30T14:59:28.946900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras.backend as K\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "## required for effictrain_test_splitnt GPU use\n",
    "import tensorflow as tf\n",
    "from keras.backend import tensorflow_backend\n",
    "from sklearn.manifold import TSNE\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from keras import backend as K\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Conv2D, Dropout, Activation, Flatten, MaxPooling2D\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "import numpy as np\n",
    "# config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "# session = tf.Session(config=config)\n",
    "# tensorflow_backend.set_session(session)\n",
    "## required for efficient GPU use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T15:00:20.952237Z",
     "start_time": "2019-11-30T15:00:20.934246Z"
    }
   },
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def fbeta_score(y_true, y_pred, beta=1):\n",
    "   \n",
    "    if beta < 0:\n",
    "        raise ValueError('The lowest choosable beta is zero (only precision).')\n",
    "\n",
    "    # If there are no true positives, fix the F score at 0 like sklearn.\n",
    "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
    "        return 0\n",
    "\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "    return fbeta_score\n",
    "\n",
    "\n",
    "def fmeasure(y_true, y_pred):\n",
    "   \n",
    "    return fbeta_score(y_true, y_pred, beta=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T15:00:21.612856Z",
     "start_time": "2019-11-30T15:00:20.955233Z"
    }
   },
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "path = os.path.join(path, \"Dataset\")\n",
    "subdistrict_income = pd.read_csv(path + \"/income.csv\")\n",
    "regional_info = pd.read_csv(path + \"/region.csv\")\n",
    "features_info = pd.read_csv(path + \"/devlopmental_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T16:46:08.875367Z",
     "start_time": "2019-10-20T16:46:08.851377Z"
    }
   },
   "outputs": [],
   "source": [
    "# columns = features_info.columns\n",
    "# print(columns)\n",
    "# columns = columns[:-2]\n",
    "# ls = []\n",
    "# for c in columns:\n",
    "#     ls.append(int(c))\n",
    "# ls = sorted(ls)\n",
    "# features = pd.DataFrame()\n",
    "# for l in ls:\n",
    "#     features    = pd.concat([features, features_info[str(l)]], axis=1, ignore_index=True).reset_index(drop=True)\n",
    "# features = pd.concat([features, features_info['Town/Village_code'], features_info['Subdistt_code']], axis=1, ignore_index=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T16:46:09.533267Z",
     "start_time": "2019-10-20T16:46:09.528274Z"
    }
   },
   "outputs": [],
   "source": [
    "# features[26] = features[26].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T16:46:09.952554Z",
     "start_time": "2019-10-20T16:46:09.948554Z"
    }
   },
   "outputs": [],
   "source": [
    "# features = features[features[26].isin(subdistrict_income['Subdistt_code'].values)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T16:47:21.203051Z",
     "start_time": "2019-10-20T16:46:10.734644Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter :  0\n",
      "Counter :  1000\n",
      "Counter :  2000\n",
      "Counter :  3000\n",
      "Counter :  4000\n",
      "Counter :  5000\n",
      "Counter :  6000\n",
      "Counter :  7000\n",
      "Counter :  8000\n",
      "Counter :  9000\n",
      "Counter :  10000\n",
      "Counter :  11000\n",
      "Counter :  12000\n",
      "Counter :  13000\n",
      "Counter :  14000\n",
      "Counter :  15000\n",
      "Counter :  16000\n",
      "Counter :  17000\n",
      "Counter :  18000\n",
      "Counter :  19000\n",
      "Counter :  20000\n",
      "Counter :  21000\n",
      "Counter :  22000\n",
      "Counter :  23000\n",
      "Counter :  24000\n",
      "Counter :  25000\n",
      "Counter :  26000\n",
      "Counter :  27000\n",
      "Counter :  28000\n",
      "Counter :  29000\n",
      "Counter :  30000\n"
     ]
    }
   ],
   "source": [
    "feature = features_info.copy(deep=True)\n",
    "cols = feature.columns\n",
    "cols = cols[3:]\n",
    "counter = 0\n",
    "for i in range(feature.shape[0]):\n",
    "    if counter %1000 == 0:\n",
    "        print(\"Counter : \",counter)\n",
    "    counter = counter +1\n",
    "    num_hh = feature.iloc[i]['Household']\n",
    "    feature.at[i, cols] = feature.iloc[i][cols]*num_hh\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T16:47:21.985242Z",
     "start_time": "2019-10-20T16:47:21.207994Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Town/Village_code  Household       0_1     0_2        0_3  \\\n",
      "Subdistt_code                                                              \n",
      "701                     21592453      81646  11124.45   80.19    415.733   \n",
      "702                     28884349     104510  18597.60   39.66    547.292   \n",
      "703                     27901335      88747  30525.20   64.60   2364.573   \n",
      "704                     17293265      67992  18674.90   28.90    340.218   \n",
      "717                     22699131      72700  20568.55   53.54    510.287   \n",
      "...                          ...        ...       ...     ...        ...   \n",
      "1005                    74585732     114590  20495.12  259.03  77756.970   \n",
      "1006                    45203524      82040  27944.31  527.08  43899.940   \n",
      "1007                    39684537      65200  16041.97   93.42    274.195   \n",
      "1008                    78639660     121310  16306.86   32.04    585.760   \n",
      "1009                    28836792      48262   8027.91   53.71    103.303   \n",
      "\n",
      "                   0_4        0_5        0_6        0_7        0_8  ...  \\\n",
      "Subdistt_code                                                       ...   \n",
      "701            297.957  25036.081   3330.954  11024.869  29684.481  ...   \n",
      "702            202.229  45436.658    533.107   2310.888  36134.087  ...   \n",
      "703            950.870  25834.422    747.176    837.138  26747.401  ...   \n",
      "704            107.417  35383.815    301.334    451.272  12273.876  ...   \n",
      "717             59.945  48026.317    304.213    997.310   1698.546  ...   \n",
      "...                ...        ...        ...        ...        ...  ...   \n",
      "1005           882.508   1112.476   2452.312   1649.847   9026.105  ...   \n",
      "1006           603.125    569.885   1285.801   2124.264   4416.463  ...   \n",
      "1007           110.067  20821.799   1889.412   1306.804  24129.128  ...   \n",
      "1008           372.307  77427.959  11293.454   1914.722  12424.947  ...   \n",
      "1009           172.249   4442.923  31946.287    883.461   2163.828  ...   \n",
      "\n",
      "                    2_16       2_17      2_18       2_19       2_20      2_21  \\\n",
      "Subdistt_code                                                                   \n",
      "701            11938.367   7299.037   192.675    204.192  59505.185   545.975   \n",
      "702            12415.040   4306.794   159.465     14.668  85719.870   828.476   \n",
      "703            14820.443   6173.502   207.707     21.969  61952.390  3545.167   \n",
      "704             7801.454   3329.305    69.194     27.067  55539.616   553.467   \n",
      "717            12444.270  10572.713   133.640     18.029  49240.534    42.413   \n",
      "...                  ...        ...       ...        ...        ...       ...   \n",
      "1005            2416.592   1191.251  1460.845  19248.955  85513.587  1800.236   \n",
      "1006            2167.457    912.776  1345.218  25586.306  49387.032   512.506   \n",
      "1007            9953.803   2306.097   134.746    111.800  52446.233   125.654   \n",
      "1008           20517.385   6634.689   388.734    661.101  92057.899   751.236   \n",
      "1009            5037.896   2264.397   168.787    482.322  39574.269   385.375   \n",
      "\n",
      "                  2_22      2_23     2_24      2_25  \n",
      "Subdistt_code                                        \n",
      "701              4.980   720.828  129.743  1104.320  \n",
      "702              3.140    49.638   39.071   985.342  \n",
      "703             10.329    19.194  282.681  1720.092  \n",
      "704              1.637    10.518   23.223   634.255  \n",
      "717              6.431    15.907    5.599   222.013  \n",
      "...                ...       ...      ...       ...  \n",
      "1005           475.860  1873.771  272.816   340.917  \n",
      "1006           202.173  1397.652  276.047   245.411  \n",
      "1007             6.371    15.510    1.990    97.308  \n",
      "1008             7.883    30.620    5.622   257.624  \n",
      "1009             1.958    17.382    2.333   327.702  \n",
      "\n",
      "[133 rows x 27 columns]\n",
      "Int64Index([ 701,  702,  703,  704,  717,  718,  719,  720,  721,  722,\n",
      "            ...\n",
      "             990,  991,  995,  996, 1004, 1005, 1006, 1007, 1008, 1009],\n",
      "           dtype='int64', name='Subdistt_code', length=133)\n"
     ]
    }
   ],
   "source": [
    "aggregated_subdistrict = feature.groupby(\"Subdistt_code\").sum()\n",
    "print(aggregated_subdistrict)\n",
    "inds = aggregated_subdistrict.index\n",
    "print(inds)\n",
    "for i in inds:\n",
    "    aggregated_subdistrict.loc[i, cols]  /= aggregated_subdistrict.loc[i]['Household']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T16:47:25.208625Z",
     "start_time": "2019-10-20T16:47:25.154655Z"
    }
   },
   "outputs": [],
   "source": [
    "y = subdistrict_income.sort_values(['Subdistt_code']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T16:47:25.731076Z",
     "start_time": "2019-10-20T16:47:25.683102Z"
    }
   },
   "outputs": [],
   "source": [
    "y = y[['00','01', '02']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdistrict_income = subdistrict_income.drop_duplicates(subset=None, keep='first', inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T16:47:26.542345Z",
     "start_time": "2019-10-20T16:47:26.537345Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T16:47:27.071264Z",
     "start_time": "2019-10-20T16:47:27.063262Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = feature.columns\n",
    "cols = cols[3:]\n",
    "train_data = aggregated_subdistrict[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T16:47:28.154005Z",
     "start_time": "2019-10-20T16:47:27.954619Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data.values, y.values, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_plot(dataset_main,label_main,title,classes):\n",
    "    #TSNE Plot for glass dataset\n",
    "    tsne = PCA(n_components=2)\n",
    "    tsne_results = tsne.fit_transform(dataset_main)\n",
    "\n",
    "    df_subset = pd.DataFrame()\n",
    "    df_subset['X'] = tsne_results[:,0]\n",
    "    df_subset['y']=label_main\n",
    "    df_subset['Y'] = tsne_results[:,1]\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.title(title)\n",
    "    sns.scatterplot(\n",
    "        x=\"X\", y=\"Y\",\n",
    "        hue=\"y\",\n",
    "        palette=sns.color_palette(\"hls\", classes),\n",
    "        data=df_subset,\n",
    "        legend=\"full\",\n",
    "        alpha=1.0\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T16:47:32.835498Z",
     "start_time": "2019-10-20T16:47:30.479782Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model2():\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(BatchNormalization(input_shape=(25,)))\n",
    "    model.add(Dense(8, input_shape=(25,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(4, input_shape=(8,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(4, input_shape=(4,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(3, input_shape=(4,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T16:47:33.903238Z",
     "start_time": "2019-10-20T16:47:32.841496Z"
    }
   },
   "outputs": [],
   "source": [
    "model = build_model2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T16:47:33.985938Z",
     "start_time": "2019-10-20T16:47:33.905283Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('Could not interpret optimizer identifier:', <keras.optimizers.RMSprop object at 0x7fb6645c1f10>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-50478332e548>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model.compile(loss=keras.losses.categorical_crossentropy,\n\u001b[1;32m      2\u001b[0m               \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRMSprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m               metrics=['accuracy'])\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m         'experimental_run_tf_function', True)\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     is_any_optimizer_v1 = any(isinstance(opt, optimizers.Optimizer)\n\u001b[1;32m    253\u001b[0m                               for opt in nest.flatten(self.optimizer))\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_set_optimizer\u001b[0;34m(self, optimizer)\u001b[0m\n\u001b[1;32m   1452\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1454\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     if (self._dtype_policy.loss_scale is not None and\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizers.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Could not interpret optimizer identifier:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: ('Could not interpret optimizer identifier:', <keras.optimizers.RMSprop object at 0x7fb6645c1f10>)"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T16:47:34.028265Z",
     "start_time": "2019-10-20T16:47:33.990898Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization (BatchNo (None, 25)                100       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 208       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 15        \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 455\n",
      "Trainable params: 367\n",
      "Non-trainable params: 88\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T16:47:49.596583Z",
     "start_time": "2019-10-20T16:47:35.018522Z"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=1000, validation_data=(X_test, y_test),shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T05:51:17.833233Z",
     "start_time": "2019-10-20T05:51:17.781266Z"
    }
   },
   "outputs": [],
   "source": [
    "y_prob = model.predict(X_test)\n",
    "print(\"Corelation for each Class\")\n",
    "print(\"For roof classes:\", pearsonr(y_test[:, 0], y_prob[:, 0]))\n",
    "print(\"For Electricity classes:\", pearsonr(y_test[:, 1], y_prob[:, 1]))\n",
    "print(\"For water sources classes:\", pearsonr(y_test[:, 2], y_prob[:, 2]))\n",
    "\n",
    "threshold = 0.1\n",
    "threshold_1= []\n",
    "accuracy_score_1 = []\n",
    "precision_score_1 = []\n",
    "recall_score_1 = []\n",
    "\n",
    "while threshold<1.0:\n",
    "    threshold_1.append(threshold)\n",
    "\n",
    "    p1m = np.copy(y_test[:, 0])\n",
    "    p1m[p1m >= threshold] = 1\n",
    "    p1m[p1m < threshold] = 0\n",
    "    frac = np.sum(p1m) / len(p1m)\n",
    "    ot = [1 if i >= threshold else 0 for i in y_test[:, 0]]\n",
    "    pt = [1 if i >= threshold else 0 for i in y_prob[:, 0]]\n",
    "    print(\"------------------------------------------------------------------------------------\")\n",
    "    print(\n",
    "        \"Threshold: \" + str(threshold)\n",
    "        + \" Accuracy: \" + str(accuracy_score(ot, pt))\n",
    "        + \" Baseline: \" + str(max(frac, 1 - frac))\n",
    "        + \" Precision: \" + str(precision_score(ot, pt))\n",
    "        + \" Recall: \" + str(recall_score(ot, pt)))\n",
    "    accuracy_score_1.append(accuracy_score(ot, pt))\n",
    "    precision_score_1.append(precision_score(ot, pt))\n",
    "    recall_score_1.append(recall_score(ot, pt))\n",
    "    threshold = threshold +  0.1 \n",
    "    \n",
    "# score = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# #print loss and accuracy\n",
    "# print('Test loss:', score[0])\n",
    "# print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T18:33:14.010669Z",
     "start_time": "2019-10-19T18:33:14.000674Z"
    }
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "#print loss and accuracy\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T21:10:58.718032Z",
     "start_time": "2019-10-19T21:10:58.710037Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T21:11:17.893259Z",
     "start_time": "2019-10-19T21:11:17.886263Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(threshold_1,recall_score_1,'r--',label=\"Recall\")\n",
    "plt.plot(threshold_1,accuracy_score_1,'b--',label=\"Accuracy\")\n",
    "plt.plot(threshold_1,precision_score_1,'y--',label=\"Precision\")\n",
    "plt.xlabel(\"Thresholds\")\n",
    "plt.ylabel(\"Evaluation Metric\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T08:13:43.621107Z",
     "start_time": "2019-10-20T08:13:42.881301Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_plot(X_train,p1m,\"Visualisation for Census Dataset for selected Subdistricts\",2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2 for feature Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input = Input(shape=(400, 400, 3), name='image_input')\n",
    "\n",
    "shared = Conv2D(512, (3, 3), padding='same', activation='relu')(image_input)\n",
    "shared = MaxPooling2D((2, 2), padding='same')(shared)\n",
    "shared = Conv2D(128, (3, 3), padding='same', activation='relu')(shared)\n",
    "shared = MaxPooling2D((2, 2), padding='same')(shared)\n",
    "shared = Dropout(0.25)(shared)\n",
    "shared = Conv2D(32, (3, 3), padding='same', activation='relu')(shared)\n",
    "shared = MaxPooling2D((2, 2), padding='same')(shared)\n",
    "shared = Dropout(0.25)(shared)\n",
    "shared = Conv2D(8, (3, 3), padding='same', activation='relu')(shared)\n",
    "shared = MaxPooling2D((2, 2), padding='same')(shared)\n",
    "shared = Dropout(0.25)(shared)\n",
    "shared = Flatten()(shared)\n",
    "\n",
    "inputA = Dense(4096, activation=\"relu\")(shared)\n",
    "inputA = Dense(2048, activation=\"relu\")(inputA)\n",
    "inputA = Dense(2048, activation=\"relu\")(inputA)\n",
    "inputA = Dense(1024, activation=\"relu\")(inputA)\n",
    "inputA = Dense(9, activation=\"relu\")(inputA)\n",
    "\n",
    "inputB = Dense(4096, activation=\"relu\")(shared)\n",
    "inputB = Dense(2048, activation=\"relu\")(inputB)\n",
    "inputB = Dense(2048, activation=\"relu\")(inputB)\n",
    "inputB = Dense(1024, activation=\"relu\")(inputB)\n",
    "inputB = Dense(6, activation=\"relu\")(inputB) \n",
    "\n",
    "inputC = Dense(4096, activation=\"relu\")(shared)\n",
    "inputC = Dense(2048, activation=\"relu\")(inputC)\n",
    "inputC = Dense(2048, activation=\"relu\")(inputC)\n",
    "inputC = Dense(1024, activation=\"relu\")(inputC)\n",
    "inputC = Dense(10, activation=\"relu\")(inputC)\n",
    " \n",
    "model = Model(inputs=[image_input], outputs=[inputA,inputB,inputC])\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=50, validation_data=([X_test], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
